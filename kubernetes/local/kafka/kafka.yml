# kafka-test-topic-create-consume-produce
apiVersion: v1
kind: Pod
metadata:
  name: "kafka-test-topic-create-consume-produce"
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: kafka-test-consume
      image: confluentinc/cp-kafka:5.0.1
      command:
        - sh
        - -c
        - |
          # Create the topic
          kafka-topics --zookeeper kafka-zookeeper:2181 --topic helm-test-topic-create-consume-produce --create --partitions 1 --replication-factor 1 --if-not-exists && \
          # Create a message
          MESSAGE="`date -u`" && \
          # Produce a test message to the topic
          echo "$MESSAGE" | kafka-console-producer --broker-list kafka:9092 --topic helm-test-topic-create-consume-produce && \
          # Consume a test message from the topic
          kafka-console-consumer --bootstrap-server kafka-headless:9092 --topic helm-test-topic-create-consume-produce --from-beginning --timeout-ms 2000 --max-messages 1 | grep "$MESSAGE"
  restartPolicy: Never
MANIFEST:

---
# Source: kafka/charts/zookeeper/templates/poddisruptionbudget.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: kafka-zookeeper
  labels:
    app: zookeeper
    chart: zookeeper-2.1.0
    release: kafka
    heritage: Tiller
    component: server
spec:
  selector:
    matchLabels:
      app: zookeeper
      release: kafka
      component: server
  maxUnavailable: 1
---
# Source: kafka/charts/zookeeper/templates/config-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-zookeeper
  labels:
    app: zookeeper
    chart: zookeeper-2.1.0
    release: kafka
    heritage: Tiller
    component: server
data:
  ok: |
    #!/bin/sh
    echo ruok | nc 127.0.0.1 ${1:-2181}

  ready: |
    #!/bin/sh
    echo ruok | nc 127.0.0.1 ${1:-2181}

  run: |
    #!/bin/bash

    set -a
    ROOT=$(echo /apache-zookeeper-*)

    ZK_USER=${ZK_USER:-"zookeeper"}
    ZK_LOG_LEVEL=${ZK_LOG_LEVEL:-"INFO"}
    ZK_DATA_DIR=${ZK_DATA_DIR:-"/data"}
    ZK_DATA_LOG_DIR=${ZK_DATA_LOG_DIR:-"/data/log"}
    ZK_CONF_DIR=${ZK_CONF_DIR:-"/conf"}
    ZK_CLIENT_PORT=${ZK_CLIENT_PORT:-2181}
    ZK_SERVER_PORT=${ZK_SERVER_PORT:-2888}
    ZK_ELECTION_PORT=${ZK_ELECTION_PORT:-3888}
    ZK_TICK_TIME=${ZK_TICK_TIME:-2000}
    ZK_INIT_LIMIT=${ZK_INIT_LIMIT:-10}
    ZK_SYNC_LIMIT=${ZK_SYNC_LIMIT:-5}
    ZK_HEAP_SIZE=${ZK_HEAP_SIZE:-2G}
    ZK_MAX_CLIENT_CNXNS=${ZK_MAX_CLIENT_CNXNS:-60}
    ZK_MIN_SESSION_TIMEOUT=${ZK_MIN_SESSION_TIMEOUT:- $((ZK_TICK_TIME*2))}
    ZK_MAX_SESSION_TIMEOUT=${ZK_MAX_SESSION_TIMEOUT:- $((ZK_TICK_TIME*20))}
    ZK_SNAP_RETAIN_COUNT=${ZK_SNAP_RETAIN_COUNT:-3}
    ZK_PURGE_INTERVAL=${ZK_PURGE_INTERVAL:-0}
    ID_FILE="$ZK_DATA_DIR/myid"
    ZK_CONFIG_FILE="$ZK_CONF_DIR/zoo.cfg"
    LOG4J_PROPERTIES="$ZK_CONF_DIR/log4j.properties"
    HOST=$(hostname)
    DOMAIN=`hostname -d`
    ZOOCFG=zoo.cfg
    ZOOCFGDIR=$ZK_CONF_DIR
    JVMFLAGS="-Xmx$ZK_HEAP_SIZE -Xms$ZK_HEAP_SIZE"

    APPJAR=$(echo $ROOT/*jar)
    CLASSPATH="${ROOT}/lib/*:${APPJAR}:${ZK_CONF_DIR}:"

    if [[ $HOST =~ (.*)-([0-9]+)$ ]]; then
        NAME=${BASH_REMATCH[1]}
        ORD=${BASH_REMATCH[2]}
        MY_ID=$((ORD+1))
    else
        echo "Failed to extract ordinal from hostname $HOST"
        exit 1
    fi

    mkdir -p $ZK_DATA_DIR
    mkdir -p $ZK_DATA_LOG_DIR
    echo $MY_ID >> $ID_FILE

    echo "clientPort=$ZK_CLIENT_PORT" >> $ZK_CONFIG_FILE
    echo "dataDir=$ZK_DATA_DIR" >> $ZK_CONFIG_FILE
    echo "dataLogDir=$ZK_DATA_LOG_DIR" >> $ZK_CONFIG_FILE
    echo "tickTime=$ZK_TICK_TIME" >> $ZK_CONFIG_FILE
    echo "initLimit=$ZK_INIT_LIMIT" >> $ZK_CONFIG_FILE
    echo "syncLimit=$ZK_SYNC_LIMIT" >> $ZK_CONFIG_FILE
    echo "maxClientCnxns=$ZK_MAX_CLIENT_CNXNS" >> $ZK_CONFIG_FILE
    echo "minSessionTimeout=$ZK_MIN_SESSION_TIMEOUT" >> $ZK_CONFIG_FILE
    echo "maxSessionTimeout=$ZK_MAX_SESSION_TIMEOUT" >> $ZK_CONFIG_FILE
    echo "autopurge.snapRetainCount=$ZK_SNAP_RETAIN_COUNT" >> $ZK_CONFIG_FILE
    echo "autopurge.purgeInterval=$ZK_PURGE_INTERVAL" >> $ZK_CONFIG_FILE
    echo "4lw.commands.whitelist=*" >> $ZK_CONFIG_FILE

    for (( i=1; i<=$ZK_REPLICAS; i++ ))
    do
        echo "server.$i=$NAME-$((i-1)).$DOMAIN:$ZK_SERVER_PORT:$ZK_ELECTION_PORT" >> $ZK_CONFIG_FILE
    done

    rm -f $LOG4J_PROPERTIES

    echo "zookeeper.root.logger=$ZK_LOG_LEVEL, CONSOLE" >> $LOG4J_PROPERTIES
    echo "zookeeper.console.threshold=$ZK_LOG_LEVEL" >> $LOG4J_PROPERTIES
    echo "zookeeper.log.threshold=$ZK_LOG_LEVEL" >> $LOG4J_PROPERTIES
    echo "zookeeper.log.dir=$ZK_DATA_LOG_DIR" >> $LOG4J_PROPERTIES
    echo "zookeeper.log.file=zookeeper.log" >> $LOG4J_PROPERTIES
    echo "zookeeper.log.maxfilesize=256MB" >> $LOG4J_PROPERTIES
    echo "zookeeper.log.maxbackupindex=10" >> $LOG4J_PROPERTIES
    echo "zookeeper.tracelog.dir=$ZK_DATA_LOG_DIR" >> $LOG4J_PROPERTIES
    echo "zookeeper.tracelog.file=zookeeper_trace.log" >> $LOG4J_PROPERTIES
    echo "log4j.rootLogger=\${zookeeper.root.logger}" >> $LOG4J_PROPERTIES
    echo "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender" >> $LOG4J_PROPERTIES
    echo "log4j.appender.CONSOLE.Threshold=\${zookeeper.console.threshold}" >> $LOG4J_PROPERTIES
    echo "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout" >> $LOG4J_PROPERTIES
    echo "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} [myid:%X{myid}] - %-5p [%t:%C{1}@%L] - %m%n" >> $LOG4J_PROPERTIES

    if [ -n "$JMXDISABLE" ]
    then
        MAIN=org.apache.zookeeper.server.quorum.QuorumPeerMain
    else
        MAIN="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=$JMXPORT -Dcom.sun.management.jmxremote.authenticate=$JMXAUTH -Dcom.sun.management.jmxremote.ssl=$JMXSSL -Dzookeeper.jmx.log4j.disable=$JMXLOG4J org.apache.zookeeper.server.quorum.QuorumPeerMain"
    fi

    set -x
    exec java -cp "$CLASSPATH" $JVMFLAGS $MAIN $ZK_CONFIG_FILE
---
# Source: kafka/charts/zookeeper/templates/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka-zookeeper-headless
  labels:
    app: zookeeper
    chart: zookeeper-2.1.0
    release: kafka
    heritage: Tiller
spec:
  clusterIP: None
  ports:
    - name: client
      port: 2181
      targetPort: client
      protocol: TCP
    - name: election
      port: 3888
      targetPort: election
      protocol: TCP
    - name: server
      port: 2888
      targetPort: server
      protocol: TCP
  selector:
    app: zookeeper
    release: kafka
---
# Source: kafka/charts/zookeeper/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka-zookeeper
  labels:
    app: zookeeper
    chart: zookeeper-2.1.0
    release: kafka
    heritage: Tiller
spec:
  type: ClusterIP
  ports:
    - name: client
      port: 2181
      protocol: TCP
      targetPort: client

  selector:
    app: zookeeper
    release: kafka
---
# Source: kafka/templates/service-brokers.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
  labels:
    helm.sh/chart: kafka-0.20.9
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: kafka-broker
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: kafka
spec:
  ports:
    - name: broker
      port: 9092
      targetPort: kafka
  selector:
    app.kubernetes.io/component: kafka-broker
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: kafka
---
# Source: kafka/templates/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  labels:
    helm.sh/chart: kafka-0.20.9
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: kafka-broker
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: kafka
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  ports:
    - name: broker
      port: 9092
  clusterIP: None
  selector:
    app.kubernetes.io/component: kafka-broker
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: kafka
---
# Source: kafka/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka-zookeeper
  labels:
    app: zookeeper
    chart: zookeeper-2.1.0
    release: kafka
    heritage: Tiller
    component: server
spec:
  serviceName: kafka-zookeeper-headless
  replicas: 3
  selector:
    matchLabels:
      app: zookeeper
      release: kafka
      component: server
  updateStrategy:
    type: RollingUpdate

  template:
    metadata:
      labels:
        app: zookeeper
        release: kafka
        component: server
    spec:
      terminationGracePeriodSeconds: 1800
      securityContext:
        fsGroup: 1000
        runAsUser: 1000

      containers:
        - name: zookeeper
          image: "zookeeper:3.5.5"
          imagePullPolicy: IfNotPresent
          command:
            - "/bin/bash"
            - "-xec"
            - "/config-scripts/run"
          ports:
            - name: client
              containerPort: 2181
              protocol: TCP

            - name: election
              containerPort: 3888
              protocol: TCP

            - name: server
              containerPort: 2888
              protocol: TCP

          livenessProbe:
            exec:
              command:
                - sh
                - /config-scripts/ok
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 2
            successThreshold: 1
          readinessProbe:
            exec:
              command:
                - sh
                - /config-scripts/ready
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 2
            successThreshold: 1
          env:
            - name: ZK_REPLICAS
              value: "3"
            - name: JMXAUTH
              value: "false"
            - name: JMXDISABLE
              value: "false"
            - name: JMXPORT
              value: "1099"
            - name: JMXSSL
              value: "false"
            - name: ZK_HEAP_SIZE
              value: "1G"
            - name: ZK_SYNC_LIMIT
              value: "10"
            - name: ZK_TICK_TIME
              value: "2000"
            - name: ZOO_AUTOPURGE_PURGEINTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_SNAPRETAINCOUNT
              value: "3"
            - name: ZOO_INIT_LIMIT
              value: "5"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_PORT
              value: "2181"
            - name: ZOO_STANDALONE_ENABLED
              value: "false"
            - name: ZOO_TICK_TIME
              value: "2000"
          resources:
            requests:
              cpu: 50m
              memory: 64M

          volumeMounts:
            - name: data
              mountPath: /data
            - name: config
              mountPath: /config-scripts
      volumes:
        - name: config
          configMap:
            name: kafka-zookeeper
            defaultMode: 0555
        - name: data
          emptyDir: {}
---
# Source: kafka/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  labels:
    helm.sh/chart: kafka-0.20.9
    app.kubernetes.io/managed-by: Tiller
    app.kubernetes.io/component: kafka-broker
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: kafka
spec:
  selector:
    matchLabels:
      app.kubernetes.io/component: kafka-broker
      app.kubernetes.io/name: kafka
      app.kubernetes.io/instance: kafka
  serviceName: kafka-headless
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: OnDelete

  replicas: 3
  template:
    metadata:
      labels:
        helm.sh/chart: kafka-0.20.9
        app.kubernetes.io/managed-by: Tiller
        app.kubernetes.io/component: kafka-broker
        app.kubernetes.io/name: kafka
        app.kubernetes.io/instance: kafka
    spec:
      containers:
        - name: kafka-broker
          image: "confluentinc/cp-kafka:5.0.1"
          imagePullPolicy: "IfNotPresent"
          livenessProbe:
            exec:
              command:
                - sh
                - -ec
                - /usr/bin/jps | /bin/grep -q SupportedKafka
            initialDelaySeconds: 30
            timeoutSeconds: 5
          readinessProbe:
            tcpSocket:
              port: kafka
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          ports:
            - containerPort: 9092
              name: kafka
          resources:
            requests:
              cpu: 50m
              memory: 64M

          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KAFKA_HEAP_OPTS
              value: -Xmx1G -Xms1G
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "kafka-zookeeper:2181"
            - name: KAFKA_LOG_DIRS
              value: "/opt/kafka/data/logs"
            - name: "KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE"
              value: "false"
            - name: KAFKA_JMX_PORT
              value: "5555"
          # This is required because the Downward API does not yet support identification of
          # pod numbering in statefulsets. Thus, we are required to specify a command which
          # allows us to extract the pod ID for usage as the Kafka Broker ID.
          # See: https://github.com/kubernetes/kubernetes/issues/31218
          command:
            - sh
            - -exc
            - |
              unset KAFKA_PORT && \
              export KAFKA_BROKER_ID=${POD_NAME##*-} && \
              export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_IP}:9092 && \
              exec /etc/confluent/docker/run
          volumeMounts:
            - name: datadir
              mountPath: "/opt/kafka/data"
      volumes:
        - name: datadir
          emptyDir: {}
      terminationGracePeriodSeconds: 60
